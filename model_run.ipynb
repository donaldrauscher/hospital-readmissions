{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donald/Documents/hospital-readmissions/venv/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, ShuffleSplit\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, FunctionTransformer\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix, roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from skl.one_hot import OneHotEncoder\n",
    "from skl.hcc import HCCEncoder\n",
    "from skl.stack import StackingClassifier\n",
    "from skl.util import add_dict_prefix, get_first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donald/Documents/hospital-readmissions/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# import our data\n",
    "admit = pd.read_csv('data/diabetic_data.csv', na_filter = True, na_values = ['?', 'None'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode medication variables\n",
    "med_var = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', \\\n",
    "           'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', \\\n",
    "           'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', 'glyburide-metformin', \\\n",
    "           'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone']\n",
    "\n",
    "for m in med_var:\n",
    "    admit['has_' + m] = admit[m].apply(lambda x: 0 if x == 'No' else 1)\n",
    "    admit['dir_' + m] = admit[m].apply(lambda x: -1 if x == 'Down' else 1 if x == 'Up' else 0)\n",
    "\n",
    "admit.drop(labels = med_var, axis = 1, inplace = True)\n",
    "admit['diabetesMed'] = admit.diabetesMed.apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "admit['change'] = admit.change.apply(lambda x: 1 if x == 'Ch' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode directional variables\n",
    "def directional_encode(df, col, val):\n",
    "    has_null = np.sum(df[col].isnull())\n",
    "    if has_null:\n",
    "        df['has_' + col] = df[col].isnull().astype(int)\n",
    "        df.loc[df[col].isnull(), [col]] = 0\n",
    "    for i,v in enumerate(val):\n",
    "        df.loc[df[col].astype(str) == v, [col]] = i\n",
    "    return df\n",
    "\n",
    "def make_range(start, stop, increment, pattern = \"[%s-%s)\"):\n",
    "    r = np.arange(start, stop + 1, increment)\n",
    "    r1, r2 = r[:-1], r[1:]\n",
    "    r = [pattern % (i[0], i[1]) for i in zip(r1, r2)]\n",
    "    r = r + ['>%s' % (stop)]\n",
    "    return r\n",
    "\n",
    "admit = directional_encode(admit, 'A1Cresult', ['Norm','>7','>8'])\n",
    "admit = directional_encode(admit, 'max_glu_serum', ['Norm','>200','>300'])\n",
    "admit = directional_encode(admit, 'weight', make_range(0, 200, 25))\n",
    "admit = directional_encode(admit, 'age', make_range(0, 100, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine diagnosis codes into array; remove missing\n",
    "diag = admit[['diag_1', 'diag_2', 'diag_3']].values\n",
    "diag = [x[~pd.isnull(x)] for x in diag]\n",
    "admit['diag'] = pd.Series(diag)\n",
    "admit['diag_first'] = pd.Series([get_first(x) for x in diag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode our y variable\n",
    "admit['readmitted'] = admit.readmitted.apply(lambda x: 1 if x == '<30' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a few columns we don't need\n",
    "drop_var = ['encounter_id', 'patient_nbr', 'diag_1', 'diag_2', 'diag_3']\n",
    "admit.drop(labels = drop_var, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "xdata = admit.drop(labels = ['readmitted'], axis = 1)\n",
    "ydata = admit.readmitted\n",
    "xdata_train, xdata_test, ydata_train, ydata_test = train_test_split(xdata, ydata, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pipelines\n",
    "cat_var = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id', \\\n",
    "           'race', 'gender', 'payer_code', 'medical_specialty', 'diag']\n",
    "\n",
    "hcc_cat_var = ['diag_first']\n",
    "\n",
    "fe1 = [\n",
    "    ('one_hot', OneHotEncoder(columns = cat_var, column_params = {'diag' : {'top_n' : 200, 'min_support' : 0}})),\n",
    "    ('hcc', HCCEncoder(columns = hcc_cat_var, column_params = {'diag_first' : {'add_noise' : False}})),\n",
    "    ('imputer', Imputer(missing_values = 'NaN', strategy = 'median')),\n",
    "    ('scaler', StandardScaler())\n",
    "]\n",
    "\n",
    "fe2 = [\n",
    "    ('filter', FunctionTransformer(lambda X: X.drop(labels = hcc_cat_var, axis = 1), validate = False)),\n",
    "    ('one_hot', OneHotEncoder(columns = cat_var, column_params = {'diag' : {'top_n' : 200, 'min_support' : 0}})),\n",
    "    ('imputer', Imputer(missing_values = 'NaN', strategy = 'median')),\n",
    "    ('scaler', StandardScaler())\n",
    "]\n",
    "\n",
    "model_stack = [\n",
    "    fe1 + [('lr', LogisticRegression(class_weight = \"balanced\"))],\n",
    "    fe2 + [('rf', RandomForestClassifier(random_state = 1, class_weight = \"balanced\"))],\n",
    "    fe2 + [('xgb', XGBClassifier(seed = 1, scale_pos_weight = (1 / np.mean(ydata_train) - 1)))]\n",
    "]\n",
    "\n",
    "model_stack = [(m[-1][0], Pipeline(steps = m)) for m in model_stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donald/Documents/hospital-readmissions/venv/lib/python2.7/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for each model individually\n",
    "ss = ShuffleSplit(n_splits = 5, train_size = 0.25, random_state = 1)\n",
    "tuning_constants = {'scoring': 'roc_auc', 'cv': ss, 'verbose': 1, 'refit': False}\n",
    "grid_search_tuning_arg = tuning_constants.copy()\n",
    "rand_search_tuning_arg = dict(tuning_constants, **{'random_state': 1, 'n_iter': 20})\n",
    "tuning_types = {'lr': GridSearchCV, 'rf': RandomizedSearchCV, 'xgb': RandomizedSearchCV}\n",
    "\n",
    "def make_tuner(cls, pipeline, params):\n",
    "    kwarg = grid_search_tuning_arg if cls is GridSearchCV else rand_search_tuning_arg\n",
    "    return cls(pipeline, params, **kwarg)\n",
    "\n",
    "param_grid = {\n",
    "    'lr': {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1, 1]\n",
    "    },\n",
    "    'rf': {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': [3, None],\n",
    "        'max_features': randint(1, 10),\n",
    "        'min_samples_split': randint(2, 10),\n",
    "        'min_samples_leaf': randint(1, 10),\n",
    "        'bootstrap': [True, False],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'xgb': {\n",
    "        'n_estimators': (np.arange(1, 6) * 100).tolist(),\n",
    "        'learning_rate': (np.arange(2, 11) / 100.0).tolist(),\n",
    "        'max_depth': (np.arange(2, 6) * 2).tolist(),\n",
    "        'min_child_weight': randint(1, 10),\n",
    "        'subsample': [0.5, 0.75, 1],\n",
    "        'colsample_bytree': [0.5, 0.75, 1]\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    with open('model_param.yaml', 'r') as f:\n",
    "        param_optimal = yaml.load(f)\n",
    "except IOError:\n",
    "    param_optimal = {}\n",
    "\n",
    "    for m in model_stack:\n",
    "        # create tuner\n",
    "        model_name, pipeline = m\n",
    "        param_grid_model = add_dict_prefix(param_grid[model_name], model_name)\n",
    "        tuner = make_tuner(tuning_types[model_name], pipeline, param_grid_model)\n",
    "\n",
    "        # use tuner to determine optimal params\n",
    "        tuner.fit(xdata_train, ydata_train)\n",
    "        print('Best %s params: %s' % (model_name, str(tuner.best_params_)))\n",
    "        print('Best %s params score: %s' % (model_name, str(tuner.best_score_)))\n",
    "\n",
    "        # save best params\n",
    "        param_optimal.update(**add_dict_prefix(tuner.best_params_, model_name))\n",
    "\n",
    "    with open('model_param.yaml', 'w') as f:\n",
    "        yaml.dump(param_optimal, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model stack\n",
    "stack = StackingClassifier(classifiers = model_stack)\n",
    "stack.set_params(**add_dict_prefix(param_optimal, 'stack'))\n",
    "stack.fit(xdata_train, ydata_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for our test set\n",
    "ydata_test_pred = stack.predict_proba(xdata_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive threshold: 0.202586877333\n",
      "Confusion matrix:\n",
      "[[16558  1607]\n",
      " [ 1607   582]]\n",
      "Stack AUC: 0.69729688404\n"
     ]
    }
   ],
   "source": [
    "# determine cutoff balancing precision/recall\n",
    "precision, recall, threshold = precision_recall_curve(ydata_test, ydata_test_pred)\n",
    "pos_threshold = np.min(threshold[precision[1:] > recall[:-1]])\n",
    "print('Positive threshold: %s' % str(pos_threshold))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(ydata_test, (ydata_test_pred >= pos_threshold).astype(int)))\n",
    "print('Stack AUC: %s' % roc_auc_score(ydata_test, ydata_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR AUC: 0.685167297338\n",
      "RF AUC: 0.693003188754\n",
      "XGB AUC: 0.692441123617\n",
      "Avg AUC: 0.696381690752\n"
     ]
    }
   ],
   "source": [
    "# ensemble versus individual models\n",
    "pred = []\n",
    "for m in stack.named_steps['stack'].transformer_list:\n",
    "    model_name, model = m\n",
    "    pred_i = model.transform(xdata_test)\n",
    "    pred.append(pred_i)\n",
    "    print('%s AUC: %s' % (model_name.upper(), roc_auc_score(ydata_test, pred_i)))\n",
    "\n",
    "avg_pred = np.average(pred, axis = 0)\n",
    "print('Avg AUC: %s' % roc_auc_score(ydata_test, avg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         coef                                            feature\n",
      "8    0.336717                                   number_inpatient\n",
      "82   0.152511                       discharge_disposition_id__22\n",
      "13   0.085836                                        diabetesMed\n",
      "71   0.085295                        discharge_disposition_id__3\n",
      "73   0.076738                        discharge_disposition_id__5\n",
      "357  0.073027                                         diag_first\n",
      "70   0.063417                        discharge_disposition_id__2\n",
      "7    0.063302                                   number_emergency\n",
      "86   0.056432                       discharge_disposition_id__28\n",
      "189  0.055940                                        diag__250.6\n",
      "0    0.048601                                                age\n",
      "232  0.042934                                          diag__403\n",
      "80   0.041979                       discharge_disposition_id__15\n",
      "9    0.039134                                   number_diagnoses\n",
      "5    0.036603                                    num_medications\n",
      "185  0.031926                                       diag__250.41\n",
      "60   0.031219                                      has_A1Cresult\n",
      "166  0.026664                                          diag__197\n",
      "176  0.026450                                       diag__250.01\n",
      "246  0.026150                                          diag__428\n",
      "126  0.024995                      medical_specialty__Hematology\n",
      "178  0.024924                                       diag__250.03\n",
      "271  0.022933                                          diag__511\n",
      "293  0.022446                                          diag__577\n",
      "168  0.022284                                          diag__202\n",
      "297  0.021268                                          diag__585\n",
      "295  0.020922                                          diag__581\n",
      "349  0.020386                                          diag__V12\n",
      "186  0.020350                                       diag__250.42\n",
      "327  0.020338                                          diag__785\n",
      "..        ...                                                ...\n",
      "90  -0.022561                             admission_source_id__4\n",
      "175 -0.023372                                          diag__250\n",
      "118 -0.023845                                     payer_code__UN\n",
      "196 -0.025124                                          diag__272\n",
      "115 -0.025480                                     payer_code__PO\n",
      "109 -0.026125                                     payer_code__HM\n",
      "121 -0.026488                medical_specialty__Emergency/Trauma\n",
      "234 -0.027651                                           diag__41\n",
      "120 -0.027736                      medical_specialty__Cardiology\n",
      "279 -0.027803                                          diag__540\n",
      "352 -0.029966                                          diag__V43\n",
      "328 -0.030321                                          diag__786\n",
      "14  -0.031050                                      has_metformin\n",
      "150 -0.031143  medical_specialty__Surgery-Cardiovascular/Thor...\n",
      "348 -0.031740                                          diag__V10\n",
      "264 -0.031911                                          diag__486\n",
      "230 -0.033747                                          diag__401\n",
      "110 -0.034196                                     payer_code__MC\n",
      "104 -0.036563                                     payer_code__BC\n",
      "125 -0.037262                      medical_specialty__Gynecology\n",
      "107 -0.038126                                     payer_code__CP\n",
      "83  -0.038866                       discharge_disposition_id__23\n",
      "226 -0.046738                                          diag__386\n",
      "79  -0.048053                       discharge_disposition_id__14\n",
      "136 -0.051263      medical_specialty__Orthopedics-Reconstructive\n",
      "137 -0.060267                  medical_specialty__Otolaryngology\n",
      "140 -0.067581        medical_specialty__Pediatrics-Endocrinology\n",
      "78  -0.068196                       discharge_disposition_id__13\n",
      "69  -0.082867                        discharge_disposition_id__1\n",
      "77  -0.523911                       discharge_disposition_id__11\n",
      "\n",
      "[259 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# importance scores (from logistic regression)\n",
    "lr_model = stack.named_steps['stack'].transformer_list[0][1]\n",
    "features = lr_model.named_steps['hcc'].get_feature_names()\n",
    "coef = lr_model.named_steps['lr'].coef_[0]\n",
    "importance = pd.DataFrame(data = {'feature' : features, 'coef' : coef})\n",
    "importance = importance.loc[importance.coef != 0,:]\n",
    "importance.sort_values(by = ['coef'], ascending = False, inplace = True)\n",
    "print(importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
